{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed seance started at: 2019-09-13 08:44:53 with user test_subject_01\n",
      "Completed seance started at: 2019-09-18 09:23:40 with user test_subject_02\n",
      "Completed seance started at: 2019-09-18 09:46:16 with user test_subject_02\n",
      "Completed seance started at: 2019-09-20 06:24:48 with user test_subject_03\n",
      "Missin data in seance... skipping.\n",
      "Completed seance started at: 2019-09-20 10:02:47 with user test_subject_04\n",
      "Completed seance started at: 2019-09-20 10:29:38 with user test_subject_04\n",
      "Completed seance started at: 2019-09-23 09:03:16 with user test_subject_05\n",
      "Completed seance started at: 2019-09-23 09:40:48 with user test_subject_05\n",
      "Completed seance started at: 2019-09-24 13:04:29 with user test_subject_06\n",
      "Missin data in seance... skipping.\n",
      "Completed seance started at: 2019-09-25 07:06:48 with user test_subject_07\n",
      "Completed seance started at: 2019-09-25 07:52:06 with user test_subject_07\n",
      "Completed seance started at: 2019-09-25 08:59:18 with user test_subject_08\n",
      "Completed seance started at: 2019-09-25 09:44:45 with user test_subject_08\n",
      "Completed seance started at: 2019-09-26 06:58:46 with user test_subject_09\n",
      "Completed seance started at: 2019-09-26 07:31:39 with user test_subject_09\n",
      "Completed seance started at: 2019-09-26 14:57:11 with user test_subject_10\n",
      "Completed seance started at: 2019-09-30 09:15:40 with user test_subject_11\n",
      "Completed seance started at: 2019-09-30 09:43:42 with user test_subject_11\n",
      "Completed seance started at: 2019-10-01 07:50:26 with user test_subject_12\n",
      "Completed seance started at: 2019-10-01 08:20:45 with user test_subject_12\n",
      "Completed seance started at: 2019-10-01 09:09:17 with user test_subject_13\n",
      "Completed seance started at: 2019-10-01 09:28:26 with user test_subject_13\n",
      "Completed seance started at: 2019-09-13 08:06:12 with user test_subject_01\n",
      "Completed seance started at: 2019-09-20 06:49:15 with user test_subject_03\n",
      "Missin data in seance... skipping.\n",
      "Completed seance started at: 2019-09-24 12:33:06 with user test_subject_06\n",
      "Completed seance started at: 2019-09-26 14:29:25 with user test_subject_10\n",
      "Completed seance started at: 2019-10-02 06:42:09 with user test_subject_14\n",
      "Completed seance started at: 2019-10-02 07:02:34 with user test_subject_14\n",
      "Completed seance started at: 2019-10-02 12:05:39 with user test_subject_15\n",
      "Completed seance started at: 2019-10-02 12:28:36 with user test_subject_15\n",
      "Completed seance started at: 2019-10-02 15:20:42 with user test_subject_16\n",
      "Completed seance started at: 2019-10-02 15:47:29 with user test_subject_16\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean, std\n",
    "\n",
    "from seances.models import Seance\n",
    "from sensors.models import SensorRecord, Sensor\n",
    "\n",
    "SENSORS = [\"fsr_01\",\"fsr_02\",\"fsr_03\",\"fsr_04\",\"accel01_x\",\"accel01_y\",\"accel01_z\",\"gyro01_x\",\"gyro01_y\",\"gyro01_z\",\"cpuusage_01\",\"cpuusage_02\",\"cpuusage_03\",\"cpuusage_04\",\"mempercentage_01\",\"netpacketssent_01\",\"netpacketsreceived_01\"]\n",
    "\n",
    "def process_data():\n",
    "    \"\"\"\n",
    "    Shape our data in a way that is usable by the autoencoder.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    seances = Seance.objects.filter(valid=True, experiment__sequence_number=1)\n",
    "    sensors = Sensor.objects.filter(topic__in=SENSORS)\n",
    "\n",
    "    for seance in seances:\n",
    "        print(seance)\n",
    "        row_data = {\"user_id\": seance.user.id, \"seance_id\": seance.id}\n",
    "        valid = True\n",
    "        for sensor in sensors:\n",
    "            try:\n",
    "                sensor_data = to_n_points(\n",
    "                    [\n",
    "                        x.value\n",
    "                        for x in SensorRecord.objects.filter(\n",
    "                            seance=seance, sensor=sensor\n",
    "                        )\n",
    "                    ],\n",
    "                    50,\n",
    "                )\n",
    "            except ValueError:\n",
    "                print(\"Missin data in seance... skipping.\")\n",
    "                valid = False\n",
    "                break\n",
    "            row_data.update({sensor.topic: sensor_data})\n",
    "        if valid:\n",
    "            data.append(row_data)\n",
    "    return data\n",
    "\n",
    "def to_n_points(data: list, n: int):\n",
    "    \"\"\"\n",
    "    Take the provided list of values and compress it to a length of n elements.\n",
    "    This is achieved by averaging elements.\n",
    "    \"\"\"\n",
    "    if len(data) < n:\n",
    "        raise ValueError(\"Not enough data to compress to {} elements.\".format(n))\n",
    "\n",
    "    step = len(data) / n\n",
    "    i = 0\n",
    "    result = []\n",
    "    for _ in range(0, n):\n",
    "        row = data[round(i) : round(i + step)]\n",
    "        result.append(mean(row))\n",
    "        i += step\n",
    "    return result\n",
    "\n",
    "data = process_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.154258801232905e-15, 3.045262423937079e-15, 7.245271757328857e-15, 5.9040802096739285e-15, -2.441727614295877e-15, -6.6117500225815775e-15, 8.260279694878584e-15, 3.03258934369075e-15, 7.616736026013976e-15, 5.113086684129753e-16, 3.050457219982873e-15, 7.951731360491444e-15, -8.181573121803775e-15, 1.897131473146074e-14, -1.1549418954270414e-15, 1.0339967050305661e-16, -2.2274929017945706e-17, 9.171220774672707e-17, 5.4449826488311727e-17, 6.819978267222883e-17, 0.0, -1.2086431880773703e-17, 3.9980813448945706e-17, -6.879968916748108e-17, 4.4629745245334743e-17, 7.624248146078018e-16, 1.1138111840897612e-15, 8.649337607181801e-16, 9.11131018704479e-16, 8.640039743589022e-16, -2.4695125702418558e-15, -1.0454763576869254e-15, -3.5529461253903206e-16, -1.5676334580745816e-15, 5.485739519739062e-17, 8.4378112104461e-17, 2.947229927850203e-16, 1.2459137214322616e-16, 3.421389947788248e-16, -1.1203925629297576e-16, -7.438290874222456e-18, 2.7194471731740832e-17, -9.042172343976674e-17, -8.367529763612564e-18, 9.414086887687798e-18, 3.8865069817812336e-16, -3.2168503313443854e-16, -2.036464573408217e-15, 9.63195648344735e-16, 1.6736154467000527e-16, 4.419541655719373e-16, 1.5585823230314696e-16, -1.7614115294533733e-16, -5.124106267500722e-16, 1.3664283380001927e-16, -3.8003788150630357e-16, -2.2951725989846985e-17, -8.86043375422e-17, 3.843079700625542e-17, 2.135044278125301e-16, 6.490534605500915e-16, 4.013883242875566e-16, -1.3023770096564337e-16, 1.176409397247041e-15, -1.078197360453277e-16, -2.6047540193128674e-16, -1.1956247957501687e-15, 4.526293869625638e-16, 6.960244346688481e-16, -5.380311580875758e-16, -2.381525775805577e-14, -1.808787038277459e-14, 1.6534392902453223e-14, -1.6696196082608496e-14, -5.1615631846608155e-17, -1.7077248706052407e-15, 1.2111523905001707e-15, -9.810334363051383e-16, 6.297992430600888e-16, 4.2551820652906e-15, 1.8974720784502674e-15, -1.1425204217051611e-15, 1.6982300339636653e-15, -2.2446690970603166e-15, -2.62416351275037e-16]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "for row in data:\n",
    "    x = []\n",
    "    for sensor in SENSORS:\n",
    "        x += row[sensor]\n",
    "    X.append(x)\n",
    "\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# this is the size of our encoded representations\n",
    "encoding_dim = 16  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(784,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation=\"relu\")(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(784, activation=\"sigmoid\")(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer=\"adadelta\", loss=\"binary_crossentropy\")\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "autoencoder.fit(\n",
    "    x_train,\n",
    "    x_train,\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    "    validation_data=(x_test, x_test),\n",
    ")\n",
    "\n",
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
