{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from seances.models import Seance\n",
    "print(\"Number of completed seances:\")\n",
    "print(Seance.objects.filter(valid=True).count())\n",
    "    \n",
    "print(\"Experiment 1 count: {}\".format(Seance.objects.filter(experiment__sequence_number=1).count()))\n",
    "print(\"Experiment 2 count: {}\".format(Seance.objects.filter(experiment__sequence_number=2).count()))\n",
    "print(\"Experiment 3 count: {}\".format(Seance.objects.filter(experiment__sequence_number=3).count()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Loading the data from the db\n",
    "# should we use Influx and interpolated data (probably not)?\n",
    "# it will take some time to calculate all features for everyone.\n",
    "\n",
    "from numpy import mean, std\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def load_data(username, seance_num, sens):\n",
    "    try:\n",
    "        seance = Seance.objects.filter(user__username=username, valid=True).order_by('created')[seance_num]\n",
    "    except IndexError:\n",
    "        print(\"Invalid seance id.\")\n",
    "        return\n",
    "    if sens == \"accelerometer\":\n",
    "        sensor_ids = [60,61,62]\n",
    "        sensors = Sensor.objects.filter(id__in=sensor_ids).order_by('id')\n",
    "        return (\n",
    "                SensorRecord.objects.filter(seance=seance, sensor=sensors[0]).order_by(\"created\"), \n",
    "                SensorRecord.objects.filter(seance=seance, sensor=sensors[1]).order_by(\"created\"), \n",
    "                SensorRecord.objects.filter(seance=seance, sensor=sensors[2]).order_by(\"created\")\n",
    "        )\n",
    "    elif sens == \"gyroscope\":\n",
    "        sensor_ids = [63,64,65]\n",
    "        sensors = Sensor.objects.filter(id__in=sensor_ids).order_by('id')\n",
    "        return (\n",
    "                SensorRecord.objects.filter(seance=seance, sensor=sensors[0]).order_by(\"created\"), \n",
    "                SensorRecord.objects.filter(seance=seance, sensor=sensors[1]).order_by(\"created\"), \n",
    "                SensorRecord.objects.filter(seance=seance, sensor=sensors[2]).order_by(\"created\")\n",
    "        )\n",
    "    elif sens == \"force\":\n",
    "        sensor_ids = [54,55,76,77]\n",
    "        sensors = Sensor.objects.filter(id__in=sensor_ids).order_by('topic')\n",
    "        return (\n",
    "                SensorRecord.objects.filter(seance=seance, sensor=sensors[0], value__gte=50).order_by(\"created\"), \n",
    "                SensorRecord.objects.filter(seance=seance, sensor=sensors[1], value__gte=50).order_by(\"created\"), \n",
    "                SensorRecord.objects.filter(seance=seance, sensor=sensors[2], value__gte=50).order_by(\"created\"), \n",
    "                SensorRecord.objects.filter(seance=seance, sensor=sensors[3], value__gte=50).order_by(\"created\")\n",
    "        )\n",
    "    elif sens == \"cpu\":\n",
    "        sensor_ids = [78,79,80,81]\n",
    "        sensors = Sensor.objects.filter(id__in=sensor_ids).order_by('topic')\n",
    "        return (\n",
    "                SensorRecord.objects.filter(seance=seance, sensor=sensors[0]).order_by(\"created\"), \n",
    "                SensorRecord.objects.filter(seance=seance, sensor=sensors[1]).order_by(\"created\"), \n",
    "                SensorRecord.objects.filter(seance=seance, sensor=sensors[2]).order_by(\"created\"), \n",
    "                SensorRecord.objects.filter(seance=seance, sensor=sensors[3]).order_by(\"created\")\n",
    "        )\n",
    "    elif sens == \"ram\":\n",
    "        sensor_ids = [82]\n",
    "        sensors = Sensor.objects.filter(id__in=sensor_ids).order_by('topic')\n",
    "        return SensorRecord.objects.filter(seance=seance, sensor=sensors[0]).order_by(\"created\")\n",
    "    elif sens == \"net\":\n",
    "        sensor_ids = [83, 84]\n",
    "        sensors = Sensor.objects.filter(id__in=sensor_ids).order_by('id')\n",
    "        return (\n",
    "            SensorRecord.objects.filter(seance=seance, sensor=sensors[0]).order_by(\"created\"),\n",
    "            SensorRecord.objects.filter(seance=seance, sensor=sensors[1]).order_by(\"created\")\n",
    "        )\n",
    "    elif sens == \"pir\":\n",
    "        sensor_ids = [58, 59, 66, 67, 68, 69]\n",
    "        sensors = Sensor.objects.filter(id__in=sensor_ids).order_by('id')\n",
    "        return (\n",
    "            SensorRecord.objects.filter(seance=seance, sensor__in=sensors).order_by(\"created\"),\n",
    "            seance.start,\n",
    "            seance.end,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Invalid sensor string.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables naming conventions\n",
    "This is done to preserve as many data as possible in ram, which reduces load times on multiple runs.\n",
    "\n",
    "sensorType_userNumber_featureName_axis_experiment\n",
    "\n",
    "- axis is only applicable with accelerometer, gyroscope and force sensors\n",
    "- experiment is only applicable if we have multiple experiments for the same person\n",
    "\n",
    "example:\n",
    "\n",
    "acc_1_val_x_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "from scipy.signal import find_peaks\n",
    "from datetime import datetime, timedelta\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "import plotly.express as px\n",
    "from plotly.express import line\n",
    "from pandas import DataFrame\n",
    "from numpy import mean, std\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "def process_signal(records):\n",
    "    \"\"\"\n",
    "    Take Django query and do basic signal processing.\n",
    "    \"\"\"\n",
    "    values = [x.value for x in records]\n",
    "    times = [x.timestamp for x in records]\n",
    "    m = mean(values)\n",
    "    s = std(values)\n",
    "    norm = [(x - m)/s for x in values]\n",
    "    \n",
    "    return values, times, norm, m, s\n",
    "\n",
    "def process_binary_signal(records):\n",
    "    \"\"\"\n",
    "    Take Django query with hall or pir data and return meaningful statistics.\n",
    "    \"\"\"\n",
    "    if len(records) == 0:\n",
    "        return [], []\n",
    "    values = [x.value for x in records]\n",
    "    times = [x.timestamp for x in records]\n",
    "    ids = [x.sensor_id for x in records]\n",
    "    return values, times, ids\n",
    "    \n",
    "def mean_crossing_rate(signal, m):\n",
    "    \"\"\"\n",
    "    Calculate mean crossing rate from signal.\n",
    "    Rate of mean crossings vs. the signal length.\n",
    "    \"\"\"\n",
    "    prev = signal[0]\n",
    "    crosses = 0\n",
    "    length = len(signal) - 1\n",
    "    \n",
    "    for curr in signal[1:]:\n",
    "        if prev <= m < curr or prev > m >=curr:\n",
    "            crosses += 1\n",
    "        prev = curr\n",
    "    return crosses/length\n",
    "\n",
    "def mean_acceleration_intensity(signal):\n",
    "    \"\"\"\n",
    "    Mean derivative of a signal.\n",
    "    \"\"\"\n",
    "    prev = signal[0]\n",
    "    length = len(signal) - 1\n",
    "    derv = []\n",
    "    \n",
    "    for curr in signal[1:]:\n",
    "        derv.append(abs(curr - prev))\n",
    "        prev = curr\n",
    "        \n",
    "    return mean(derv)\n",
    "    \n",
    "\n",
    "def create_time_chunks(start: datetime, end: datetime, interval: timedelta):\n",
    "    \"\"\"\n",
    "    Create a list of time intervals for given parameters.\n",
    "    \"\"\"\n",
    "    intervals = []\n",
    "    while start < end:\n",
    "        intervals.append((start, min(start + interval, end)))\n",
    "        start += interval\n",
    "    return intervals\n",
    "\n",
    "\n",
    "def join_accelerometer_signals(x, y, z):\n",
    "    \"\"\"\n",
    "    Join accelerometer signals, based simply on concurrence. \n",
    "    We can do this, as only one controller sends data in loop for all axis.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    n = min(len(x), len(y), len(z))\n",
    "    for a,b,c in zip(x[:n], y[:n], z[:n]):\n",
    "        result.append(sqrt(a**2+b**2+c**2))\n",
    "    return result, mean(result), std(result)\n",
    "\n",
    "\n",
    "def join_cpu_signals(a, b, c, d):\n",
    "    \"\"\"\n",
    "    Similar to accelerometer one.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    n = min(len(a), len(b), len(c), len(d))\n",
    "    for w,x,y,z in zip(a[:n], b[:n], c[:n], d[:n]):\n",
    "        result.append(sqrt(w**2+x**2+y**2+z**2))\n",
    "    return result, mean(result), std(result)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accelerometer data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "users = [\"test_subject_10\", \"test_subject_11\", \"test_subject_12\", \"test_subject_13\"]\n",
    "\n",
    "accx11, accy11, accz11 = load_data(users[0], 0, \"accelerometer\")\n",
    "accx12, accy12, accz12 = load_data(users[0], 3, \"accelerometer\")\n",
    "accx21, accy21, accz21 = load_data(users[1], 0, \"accelerometer\")\n",
    "accx22, accy22, accz22 = load_data(users[1], 3, \"accelerometer\")\n",
    "accx31, accy31, accz31 = load_data(users[2], 0, \"accelerometer\")\n",
    "accx32, accy32, accz32 = load_data(users[2], 3, \"accelerometer\")\n",
    "accx41, accy41, accz41 = load_data(users[3], 0, \"accelerometer\")\n",
    "accx42, accy42, accz42 = load_data(users[3], 3, \"accelerometer\")\n",
    "\n",
    "acc_1_val_x_1, _, acc_1_nor_x_1, acc_1_mea_x_1, acc_1_std_x_1 = process_signal(accx11)\n",
    "acc_1_val_y_1, _, acc_1_nor_y_1, acc_1_mea_y_1, acc_1_std_y_1 = process_signal(accy11)\n",
    "acc_1_val_z_1, _, acc_1_nor_z_1, acc_1_mea_z_1, acc_1_std_z_1 = process_signal(accz11)\n",
    "acc_1_val_x_2, _, acc_1_nor_x_2, acc_1_mea_x_2, acc_1_std_x_2 = process_signal(accx12)\n",
    "acc_1_val_y_2, _, acc_1_nor_y_2, acc_1_mea_y_2, acc_1_std_y_2 = process_signal(accy12)\n",
    "acc_1_val_z_2, _, acc_1_nor_z_2, acc_1_mea_z_2, acc_1_std_z_2 = process_signal(accz12)\n",
    "acc_1_nor_1, acc_1_mea_1, acc_1_std_1 = join_accelerometer_signals(acc_1_nor_x_1, acc_1_nor_y_1, acc_1_nor_z_1)\n",
    "acc_1_nor_2, acc_1_mea_2, acc_1_std_2 = join_accelerometer_signals(acc_1_nor_x_2, acc_1_nor_y_2, acc_1_nor_z_2)\n",
    "\n",
    "acc_2_val_x_1, _, acc_2_nor_x_1, acc_2_mea_x_1, acc_2_std_x_1 = process_signal(accx21)\n",
    "acc_2_val_y_1, _, acc_2_nor_y_1, acc_2_mea_y_1, acc_2_std_y_1 = process_signal(accy21)\n",
    "acc_2_val_z_1, _, acc_2_nor_z_1, acc_2_mea_z_1, acc_2_std_z_1 = process_signal(accz21)\n",
    "acc_2_val_x_2, _, acc_2_nor_x_2, acc_2_mea_x_2, acc_2_std_x_2 = process_signal(accx22)\n",
    "acc_2_val_y_2, _, acc_2_nor_y_2, acc_2_mea_y_2, acc_2_std_y_2 = process_signal(accy22)\n",
    "acc_2_val_z_2, _, acc_2_nor_z_2, acc_2_mea_z_2, acc_2_std_z_2 = process_signal(accz22)\n",
    "acc_2_nor_1, acc_2_mea_1, acc_2_std_1 = join_accelerometer_signals(acc_2_nor_x_1, acc_2_nor_y_1, acc_2_nor_z_1)\n",
    "acc_2_nor_2, acc_2_mea_2, acc_2_std_2 = join_accelerometer_signals(acc_2_nor_x_2, acc_2_nor_y_2, acc_2_nor_z_2)\n",
    "\n",
    "acc_3_val_x_1, _, acc_3_nor_x_1, acc_3_mea_x_1, acc_3_std_x_1 = process_signal(accx31)\n",
    "acc_3_val_y_1, _, acc_3_nor_y_1, acc_3_mea_y_1, acc_3_std_y_1 = process_signal(accy31)\n",
    "acc_3_val_z_1, _, acc_3_nor_z_1, acc_3_mea_z_1, acc_3_std_z_1 = process_signal(accz31)\n",
    "acc_3_val_x_2, _, acc_3_nor_x_2, acc_3_mea_x_2, acc_3_std_x_2 = process_signal(accx32)\n",
    "acc_3_val_y_2, _, acc_3_nor_y_2, acc_3_mea_y_2, acc_3_std_y_2 = process_signal(accy32)\n",
    "acc_3_val_z_2, _, acc_3_nor_z_2, acc_3_mea_z_2, acc_3_std_z_2 = process_signal(accz32)\n",
    "acc_3_nor_1, acc_3_mea_1, acc_3_std_1 = join_accelerometer_signals(acc_3_nor_x_1, acc_3_nor_y_1, acc_3_nor_z_1)\n",
    "acc_3_nor_2, acc_3_mea_2, acc_3_std_2 = join_accelerometer_signals(acc_3_nor_x_2, acc_3_nor_y_2, acc_3_nor_z_2)\n",
    "\n",
    "acc_4_val_x_1, _, acc_4_nor_x_1, acc_4_mea_x_1, acc_4_std_x_1 = process_signal(accx41)\n",
    "acc_4_val_y_1, _, acc_4_nor_y_1, acc_4_mea_y_1, acc_4_std_y_1 = process_signal(accy41)\n",
    "acc_4_val_z_1, _, acc_4_nor_z_1, acc_4_mea_z_1, acc_4_std_z_1 = process_signal(accz41)\n",
    "acc_4_val_x_2, _, acc_4_nor_x_2, acc_4_mea_x_2, acc_4_std_x_2 = process_signal(accx42)\n",
    "acc_4_val_y_2, _, acc_4_nor_y_2, acc_4_mea_y_2, acc_4_std_y_2 = process_signal(accy42)\n",
    "acc_4_val_z_2, _, acc_4_nor_z_2, acc_4_mea_z_2, acc_4_std_z_2 = process_signal(accz42)\n",
    "acc_4_nor_1, acc_4_mea_1, acc_4_std_1 = join_accelerometer_signals(acc_4_nor_x_1, acc_4_nor_y_1, acc_4_nor_z_1)\n",
    "acc_4_nor_2, acc_4_mea_2, acc_4_std_2 = join_accelerometer_signals(acc_4_nor_x_2, acc_4_nor_y_2, acc_4_nor_z_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stats = DataFrame(acc_1_nor_1, columns=[\"values\"])\n",
    "fig = px.line(stats, y=\"values\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"X mean values:\")\n",
    "print(acc_1_mea_x_1)\n",
    "print(acc_1_mea_x_2)\n",
    "print(acc_2_mea_x_1)\n",
    "print(acc_2_mea_x_2)\n",
    "print(acc_3_mea_x_1)\n",
    "print(acc_3_mea_x_2)\n",
    "print(acc_4_mea_x_1)\n",
    "print(acc_4_mea_x_2)\n",
    "print()\n",
    "print(\"Y mean values:\")\n",
    "print(acc_1_mea_y_1)\n",
    "print(acc_1_mea_y_2)\n",
    "print(acc_2_mea_y_1)\n",
    "print(acc_2_mea_y_2)\n",
    "print(acc_3_mea_y_1)\n",
    "print(acc_3_mea_y_2)\n",
    "print(acc_4_mea_y_1)\n",
    "print(acc_4_mea_y_2)\n",
    "print()\n",
    "print(\"Z mean values:\")\n",
    "print(acc_1_mea_z_1)\n",
    "print(acc_1_mea_z_2)\n",
    "print(acc_2_mea_z_1)\n",
    "print(acc_2_mea_z_2)\n",
    "print(acc_3_mea_z_1)\n",
    "print(acc_3_mea_z_2)\n",
    "print(acc_4_mea_z_1)\n",
    "print(acc_4_mea_z_2)\n",
    "print()\n",
    "print(\"Combined mean values:\")\n",
    "print(acc_1_mea_1)\n",
    "print(acc_1_mea_2)\n",
    "print(acc_2_mea_1)\n",
    "print(acc_2_mea_2)\n",
    "print(acc_3_mea_1)\n",
    "print(acc_3_mea_2)\n",
    "print(acc_4_mea_1)\n",
    "print(acc_4_mea_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"X stdn values:\")\n",
    "print(acc_1_std_x_1)\n",
    "print(acc_1_std_x_2)\n",
    "print(acc_2_std_x_1)\n",
    "print(acc_2_std_x_2)\n",
    "print(acc_3_std_x_1)\n",
    "print(acc_3_std_x_2)\n",
    "print(acc_4_std_x_1)\n",
    "print(acc_4_std_x_2)\n",
    "print()\n",
    "print(\"Y stdn values:\")\n",
    "print(acc_1_std_y_1)\n",
    "print(acc_1_std_y_2)\n",
    "print(acc_2_std_y_1)\n",
    "print(acc_2_std_y_2)\n",
    "print(acc_3_std_y_1)\n",
    "print(acc_3_std_y_2)\n",
    "print(acc_4_std_y_1)\n",
    "print(acc_4_std_y_2)\n",
    "print()\n",
    "print(\"Z stdn values:\")\n",
    "print(acc_1_std_z_1)\n",
    "print(acc_1_std_z_2)\n",
    "print(acc_2_std_z_1)\n",
    "print(acc_2_std_z_2)\n",
    "print(acc_3_std_z_1)\n",
    "print(acc_3_std_z_2)\n",
    "print(acc_4_std_z_1)\n",
    "print(acc_4_std_z_2)\n",
    "print()\n",
    "print(\"Combined stdn values:\")\n",
    "print(acc_1_std_1)\n",
    "print(acc_1_std_2)\n",
    "print(acc_2_std_1)\n",
    "print(acc_2_std_2)\n",
    "print(acc_3_std_1)\n",
    "print(acc_3_std_2)\n",
    "print(acc_4_std_1)\n",
    "print(acc_4_std_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean crossing rate\n",
    "- use time warping on values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"X mean crossing rate:\")\n",
    "print(mean_crossing_rate(acc_1_val_x_1, acc_1_mea_x_1))\n",
    "print(mean_crossing_rate(acc_1_val_x_2, acc_1_mea_x_2))\n",
    "print(mean_crossing_rate(acc_2_val_x_1, acc_2_mea_x_1))\n",
    "print(mean_crossing_rate(acc_2_val_x_2, acc_2_mea_x_2))\n",
    "print(mean_crossing_rate(acc_3_val_x_1, acc_3_mea_x_1))\n",
    "print(mean_crossing_rate(acc_3_val_x_2, acc_3_mea_x_2))\n",
    "print(mean_crossing_rate(acc_4_val_x_1, acc_4_mea_x_1))\n",
    "print(mean_crossing_rate(acc_4_val_x_2, acc_4_mea_x_2))\n",
    "print()\n",
    "print(\"Y mean crossing rate:\")\n",
    "print(mean_crossing_rate(acc_1_val_y_1, acc_1_mea_y_1))\n",
    "print(mean_crossing_rate(acc_1_val_y_2, acc_1_mea_y_2))\n",
    "print(mean_crossing_rate(acc_2_val_y_1, acc_2_mea_y_1))\n",
    "print(mean_crossing_rate(acc_2_val_y_2, acc_2_mea_y_2))\n",
    "print(mean_crossing_rate(acc_3_val_y_1, acc_3_mea_y_1))\n",
    "print(mean_crossing_rate(acc_3_val_y_2, acc_3_mea_y_2))\n",
    "print(mean_crossing_rate(acc_4_val_y_1, acc_4_mea_y_1))\n",
    "print(mean_crossing_rate(acc_4_val_y_2, acc_4_mea_y_2))\n",
    "print()\n",
    "print(\"Z mean crossing rate:\")\n",
    "print(mean_crossing_rate(acc_1_val_z_1, acc_1_mea_z_1))\n",
    "print(mean_crossing_rate(acc_1_val_z_2, acc_1_mea_z_2))\n",
    "print(mean_crossing_rate(acc_2_val_z_1, acc_2_mea_z_1))\n",
    "print(mean_crossing_rate(acc_2_val_z_2, acc_2_mea_z_2))\n",
    "print(mean_crossing_rate(acc_3_val_z_1, acc_3_mea_z_1))\n",
    "print(mean_crossing_rate(acc_3_val_z_2, acc_3_mea_z_2))\n",
    "print(mean_crossing_rate(acc_4_val_z_1, acc_4_mea_z_1))\n",
    "print(mean_crossing_rate(acc_4_val_z_2, acc_4_mea_z_2))\n",
    "print()\n",
    "print(\"Combined crossing rate:\")\n",
    "print(mean_crossing_rate(acc_1_nor_1, acc_1_mea_1))\n",
    "print(mean_crossing_rate(acc_1_nor_2, acc_1_mea_2))\n",
    "print(mean_crossing_rate(acc_2_nor_1, acc_2_mea_1))\n",
    "print(mean_crossing_rate(acc_2_nor_2, acc_2_mea_2))\n",
    "print(mean_crossing_rate(acc_3_nor_1, acc_3_mea_1))\n",
    "print(mean_crossing_rate(acc_3_nor_2, acc_3_mea_2))\n",
    "print(mean_crossing_rate(acc_4_nor_1, acc_4_mea_1))\n",
    "print(mean_crossing_rate(acc_4_nor_2, acc_4_mea_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean acceleration intensity\n",
    "- Calculated by taking the mean derivative of a signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"X mean acceleration intensity:\")\n",
    "print(mean_acceleration_intensity(acc_1_val_x_1))\n",
    "print(mean_acceleration_intensity(acc_1_val_x_2))\n",
    "print(mean_acceleration_intensity(acc_2_val_x_1))\n",
    "print(mean_acceleration_intensity(acc_2_val_x_2))\n",
    "print(mean_acceleration_intensity(acc_3_val_x_1))\n",
    "print(mean_acceleration_intensity(acc_3_val_x_2))\n",
    "print(mean_acceleration_intensity(acc_4_val_x_1))\n",
    "print(mean_acceleration_intensity(acc_4_val_x_2))\n",
    "print()\n",
    "print(\"Y mean acceleration intensity:\")\n",
    "print(mean_acceleration_intensity(acc_1_val_y_1))\n",
    "print(mean_acceleration_intensity(acc_1_val_y_2))\n",
    "print(mean_acceleration_intensity(acc_2_val_y_1))\n",
    "print(mean_acceleration_intensity(acc_2_val_y_2))\n",
    "print(mean_acceleration_intensity(acc_3_val_y_1))\n",
    "print(mean_acceleration_intensity(acc_3_val_y_2))\n",
    "print(mean_acceleration_intensity(acc_4_val_y_1))\n",
    "print(mean_acceleration_intensity(acc_4_val_y_2))\n",
    "print()\n",
    "print(\"Z mean acceleration intensity:\")\n",
    "print(mean_acceleration_intensity(acc_1_val_z_1))\n",
    "print(mean_acceleration_intensity(acc_1_val_z_2))\n",
    "print(mean_acceleration_intensity(acc_2_val_z_1))\n",
    "print(mean_acceleration_intensity(acc_2_val_z_2))\n",
    "print(mean_acceleration_intensity(acc_3_val_z_1))\n",
    "print(mean_acceleration_intensity(acc_3_val_z_2))\n",
    "print(mean_acceleration_intensity(acc_4_val_z_1))\n",
    "print(mean_acceleration_intensity(acc_4_val_z_2))\n",
    "print()\n",
    "print(\"Combined acceleration intensity:\")\n",
    "print(mean_acceleration_intensity(acc_1_nor_1))\n",
    "print(mean_acceleration_intensity(acc_1_nor_2))\n",
    "print(mean_acceleration_intensity(acc_2_nor_1))\n",
    "print(mean_acceleration_intensity(acc_2_nor_2))\n",
    "print(mean_acceleration_intensity(acc_3_nor_1))\n",
    "print(mean_acceleration_intensity(acc_3_nor_2))\n",
    "print(mean_acceleration_intensity(acc_4_nor_1))\n",
    "print(mean_acceleration_intensity(acc_4_nor_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "intensity = sum of square (not normalized values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic type warping example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = np.array([[1,1], [2,2], [3,3], [4,4], [5,5]])\n",
    "y = np.array([[2,2], [3,3], [3,3], [4,4]])\n",
    "\n",
    "distance, path = fastdtw(x, y, dist=euclidean)\n",
    "print(distance)\n",
    "print(path)\n",
    "\n",
    "# binarizacija glede na nek threshold, potem pa match ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gyroscope data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "users = [\"test_subject_10\", \"test_subject_11\", \"test_subject_12\", \"test_subject_13\"]\n",
    "\n",
    "gyrx11, gyry11, gyrz11 = load_data(users[0], 0, \"gyroscope\")\n",
    "gyrx12, gyry12, gyrz12 = load_data(users[0], 3, \"gyroscope\")\n",
    "gyrx21, gyry21, gyrz21 = load_data(users[1], 0, \"gyroscope\")\n",
    "gyrx22, gyry22, gyrz22 = load_data(users[1], 3, \"gyroscope\")\n",
    "gyrx31, gyry31, gyrz31 = load_data(users[2], 0, \"gyroscope\")\n",
    "gyrx32, gyry32, gyrz32 = load_data(users[2], 3, \"gyroscope\")\n",
    "gyrx41, gyry41, gyrz41 = load_data(users[3], 0, \"gyroscope\")\n",
    "gyrx42, gyry42, gyrz42 = load_data(users[3], 3, \"gyroscope\")\n",
    "\n",
    "gyr_1_val_x_1, _, gyr_1_nor_x_1, gyr_1_mea_x_1, gyr_1_std_x_1 = process_signal(gyrx11)\n",
    "gyr_1_val_y_1, _, gyr_1_nor_y_1, gyr_1_mea_y_1, gyr_1_std_y_1 = process_signal(gyry11)\n",
    "gyr_1_val_z_1, _, gyr_1_nor_z_1, gyr_1_mea_z_1, gyr_1_std_z_1 = process_signal(gyrz11)\n",
    "gyr_1_val_x_2, _, gyr_1_nor_x_2, gyr_1_mea_x_2, gyr_1_std_x_2 = process_signal(gyrx12)\n",
    "gyr_1_val_y_2, _, gyr_1_nor_y_2, gyr_1_mea_y_2, gyr_1_std_y_2 = process_signal(gyry12)\n",
    "gyr_1_val_z_2, _, gyr_1_nor_z_2, gyr_1_mea_z_2, gyr_1_std_z_2 = process_signal(gyrz12)\n",
    "gyr_1_nor_1, gyr_1_mea_1, gyr_1_std_1 = join_accelerometer_signals(gyr_1_nor_x_1, gyr_1_nor_y_1, gyr_1_nor_z_1)\n",
    "gyr_1_nor_2, gyr_1_mea_2, gyr_1_std_2 = join_accelerometer_signals(gyr_1_nor_x_2, gyr_1_nor_y_2, gyr_1_nor_z_2)\n",
    "\n",
    "gyr_2_val_x_1, _, gyr_2_nor_x_1, gyr_2_mea_x_1, gyr_2_std_x_1 = process_signal(gyrx21)\n",
    "gyr_2_val_y_1, _, gyr_2_nor_y_1, gyr_2_mea_y_1, gyr_2_std_y_1 = process_signal(gyry21)\n",
    "gyr_2_val_z_1, _, gyr_2_nor_z_1, gyr_2_mea_z_1, gyr_2_std_z_1 = process_signal(gyrz21)\n",
    "gyr_2_val_x_2, _, gyr_2_nor_x_2, gyr_2_mea_x_2, gyr_2_std_x_2 = process_signal(gyrx22)\n",
    "gyr_2_val_y_2, _, gyr_2_nor_y_2, gyr_2_mea_y_2, gyr_2_std_y_2 = process_signal(gyry22)\n",
    "gyr_2_val_z_2, _, gyr_2_nor_z_2, gyr_2_mea_z_2, gyr_2_std_z_2 = process_signal(gyrz22)\n",
    "gyr_2_nor_1, gyr_2_mea_1, gyr_2_std_1 = join_accelerometer_signals(gyr_2_nor_x_1, gyr_2_nor_y_1, gyr_2_nor_z_1)\n",
    "gyr_2_nor_2, gyr_2_mea_2, gyr_2_std_2 = join_accelerometer_signals(gyr_2_nor_x_2, gyr_2_nor_y_2, gyr_2_nor_z_2)\n",
    "\n",
    "gyr_3_val_x_1, _, gyr_3_nor_x_1, gyr_3_mea_x_1, gyr_3_std_x_1 = process_signal(gyrx31)\n",
    "gyr_3_val_y_1, _, gyr_3_nor_y_1, gyr_3_mea_y_1, gyr_3_std_y_1 = process_signal(gyry31)\n",
    "gyr_3_val_z_1, _, gyr_3_nor_z_1, gyr_3_mea_z_1, gyr_3_std_z_1 = process_signal(gyrz31)\n",
    "gyr_3_val_x_2, _, gyr_3_nor_x_2, gyr_3_mea_x_2, gyr_3_std_x_2 = process_signal(gyrx32)\n",
    "gyr_3_val_y_2, _, gyr_3_nor_y_2, gyr_3_mea_y_2, gyr_3_std_y_2 = process_signal(gyry32)\n",
    "gyr_3_val_z_2, _, gyr_3_nor_z_2, gyr_3_mea_z_2, gyr_3_std_z_2 = process_signal(gyrz32)\n",
    "gyr_3_nor_1, gyr_3_mea_1, gyr_3_std_1 = join_accelerometer_signals(gyr_3_nor_x_1, gyr_3_nor_y_1, gyr_3_nor_z_1)\n",
    "gyr_3_nor_2, gyr_3_mea_2, gyr_3_std_2 = join_accelerometer_signals(gyr_3_nor_x_2, gyr_3_nor_y_2, gyr_3_nor_z_2)\n",
    "\n",
    "gyr_4_val_x_1, _, gyr_4_nor_x_1, gyr_4_mea_x_1, gyr_4_std_x_1 = process_signal(gyrx41)\n",
    "gyr_4_val_y_1, _, gyr_4_nor_y_1, gyr_4_mea_y_1, gyr_4_std_y_1 = process_signal(gyry41)\n",
    "gyr_4_val_z_1, _, gyr_4_nor_z_1, gyr_4_mea_z_1, gyr_4_std_z_1 = process_signal(gyrz41)\n",
    "gyr_4_val_x_2, _, gyr_4_nor_x_2, gyr_4_mea_x_2, gyr_4_std_x_2 = process_signal(gyrx42)\n",
    "gyr_4_val_y_2, _, gyr_4_nor_y_2, gyr_4_mea_y_2, gyr_4_std_y_2 = process_signal(gyry42)\n",
    "gyr_4_val_z_2, _, gyr_4_nor_z_2, gyr_4_mea_z_2, gyr_4_std_z_2 = process_signal(gyrz42)\n",
    "gyr_4_nor_1, gyr_4_mea_1, gyr_4_std_1 = join_accelerometer_signals(gyr_4_nor_x_1, gyr_4_nor_y_1, gyr_4_nor_z_1)\n",
    "gyr_4_nor_2, gyr_4_mea_2, gyr_4_std_2 = join_accelerometer_signals(gyr_4_nor_x_2, gyr_4_nor_y_2, gyr_4_nor_z_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stats = DataFrame(gyr_1_nor_1, columns=[\"values\"])\n",
    "fig = px.line(stats, y=\"values\")\n",
    "fig.show()\n",
    "\n",
    "stats = DataFrame(gyr_1_nor_2, columns=[\"values\"])\n",
    "fig = px.line(stats, y=\"values\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"X mean values:\")\n",
    "print(gyr_1_mea_x_1)\n",
    "print(gyr_1_mea_x_2)\n",
    "print(gyr_2_mea_x_1)\n",
    "print(gyr_2_mea_x_2)\n",
    "print(gyr_3_mea_x_1)\n",
    "print(gyr_3_mea_x_2)\n",
    "print(gyr_4_mea_x_1)\n",
    "print(gyr_4_mea_x_2)\n",
    "print()\n",
    "print(\"Y mean values:\")\n",
    "print(gyr_1_mea_y_1)\n",
    "print(gyr_1_mea_y_2)\n",
    "print(gyr_2_mea_y_1)\n",
    "print(gyr_2_mea_y_2)\n",
    "print(gyr_3_mea_y_1)\n",
    "print(gyr_3_mea_y_2)\n",
    "print(gyr_4_mea_y_1)\n",
    "print(gyr_4_mea_y_2)\n",
    "print()\n",
    "print(\"Z mean values:\")\n",
    "print(gyr_1_mea_z_1)\n",
    "print(gyr_1_mea_z_2)\n",
    "print(gyr_2_mea_z_1)\n",
    "print(gyr_2_mea_z_2)\n",
    "print(gyr_3_mea_z_1)\n",
    "print(gyr_3_mea_z_2)\n",
    "print(gyr_4_mea_z_1)\n",
    "print(gyr_4_mea_z_2)\n",
    "print()\n",
    "print(\"Combined mean values:\")\n",
    "print(gyr_1_mea_1)\n",
    "print(gyr_1_mea_2)\n",
    "print(gyr_2_mea_1)\n",
    "print(gyr_2_mea_2)\n",
    "print(gyr_3_mea_1)\n",
    "print(gyr_3_mea_2)\n",
    "print(gyr_4_mea_1)\n",
    "print(gyr_4_mea_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"X stdn values:\")\n",
    "print(gyr_1_std_x_1)\n",
    "print(gyr_1_std_x_2)\n",
    "print(gyr_2_std_x_1)\n",
    "print(gyr_2_std_x_2)\n",
    "print(gyr_3_std_x_1)\n",
    "print(gyr_3_std_x_2)\n",
    "print(gyr_4_std_x_1)\n",
    "print(gyr_4_std_x_2)\n",
    "print()\n",
    "print(\"Y stdn values:\")\n",
    "print(gyr_1_std_y_1)\n",
    "print(gyr_1_std_y_2)\n",
    "print(gyr_2_std_y_1)\n",
    "print(gyr_2_std_y_2)\n",
    "print(gyr_3_std_y_1)\n",
    "print(gyr_3_std_y_2)\n",
    "print(gyr_4_std_y_1)\n",
    "print(gyr_4_std_y_2)\n",
    "print()\n",
    "print(\"Z stdn values:\")\n",
    "print(gyr_1_std_z_1)\n",
    "print(gyr_1_std_z_2)\n",
    "print(gyr_2_std_z_1)\n",
    "print(gyr_2_std_z_2)\n",
    "print(gyr_3_std_z_1)\n",
    "print(gyr_3_std_z_2)\n",
    "print(gyr_4_std_z_1)\n",
    "print(gyr_4_std_z_2)\n",
    "print()\n",
    "print(\"Combined stdn values:\")\n",
    "print(gyr_1_std_1)\n",
    "print(gyr_1_std_2)\n",
    "print(gyr_2_std_1)\n",
    "print(gyr_2_std_2)\n",
    "print(gyr_3_std_1)\n",
    "print(gyr_3_std_2)\n",
    "print(gyr_4_std_1)\n",
    "print(gyr_4_std_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean crossing rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"X mean crossing rate:\")\n",
    "print(mean_crossing_rate(gyr_1_val_x_1, gyr_1_mea_x_1))\n",
    "print(mean_crossing_rate(gyr_1_val_x_2, gyr_1_mea_x_2))\n",
    "print(mean_crossing_rate(gyr_2_val_x_1, gyr_2_mea_x_1))\n",
    "print(mean_crossing_rate(gyr_2_val_x_2, gyr_2_mea_x_2))\n",
    "print(mean_crossing_rate(gyr_3_val_x_1, gyr_3_mea_x_1))\n",
    "print(mean_crossing_rate(gyr_3_val_x_2, gyr_3_mea_x_2))\n",
    "print(mean_crossing_rate(gyr_4_val_x_1, gyr_4_mea_x_1))\n",
    "print(mean_crossing_rate(gyr_4_val_x_2, gyr_4_mea_x_2))\n",
    "print()\n",
    "print(\"Y mean crossing rate:\")\n",
    "print(mean_crossing_rate(gyr_1_val_y_1, gyr_1_mea_y_1))\n",
    "print(mean_crossing_rate(gyr_1_val_y_2, gyr_1_mea_y_2))\n",
    "print(mean_crossing_rate(gyr_2_val_y_1, gyr_2_mea_y_1))\n",
    "print(mean_crossing_rate(gyr_2_val_y_2, gyr_2_mea_y_2))\n",
    "print(mean_crossing_rate(gyr_3_val_y_1, gyr_3_mea_y_1))\n",
    "print(mean_crossing_rate(gyr_3_val_y_2, gyr_3_mea_y_2))\n",
    "print(mean_crossing_rate(gyr_4_val_y_1, gyr_4_mea_y_1))\n",
    "print(mean_crossing_rate(gyr_4_val_y_2, gyr_4_mea_y_2))\n",
    "print()\n",
    "print(\"Z mean crossing rate:\")\n",
    "print(mean_crossing_rate(gyr_1_val_z_1, gyr_1_mea_z_1))\n",
    "print(mean_crossing_rate(gyr_1_val_z_2, gyr_1_mea_z_2))\n",
    "print(mean_crossing_rate(gyr_2_val_z_1, gyr_2_mea_z_1))\n",
    "print(mean_crossing_rate(gyr_2_val_z_2, gyr_2_mea_z_2))\n",
    "print(mean_crossing_rate(gyr_3_val_z_1, gyr_3_mea_z_1))\n",
    "print(mean_crossing_rate(gyr_3_val_z_2, gyr_3_mea_z_2))\n",
    "print(mean_crossing_rate(gyr_4_val_z_1, gyr_4_mea_z_1))\n",
    "print(mean_crossing_rate(gyr_4_val_z_2, gyr_4_mea_z_2))\n",
    "print()\n",
    "print(\"Combined crossing rate:\")\n",
    "print(mean_crossing_rate(gyr_1_nor_1, gyr_1_mea_1))\n",
    "print(mean_crossing_rate(gyr_1_nor_2, gyr_1_mea_2))\n",
    "print(mean_crossing_rate(gyr_2_nor_1, gyr_2_mea_1))\n",
    "print(mean_crossing_rate(gyr_2_nor_2, gyr_2_mea_2))\n",
    "print(mean_crossing_rate(gyr_3_nor_1, gyr_3_mea_1))\n",
    "print(mean_crossing_rate(gyr_3_nor_2, gyr_3_mea_2))\n",
    "print(mean_crossing_rate(gyr_4_nor_1, gyr_4_mea_1))\n",
    "print(mean_crossing_rate(gyr_4_nor_2, gyr_4_mea_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Force sensors data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "users = [\"test_subject_10\", \"test_subject_11\", \"test_subject_12\", \"test_subject_13\"]\n",
    "fsra11, fsrb11, fsrc11, fsrd11 = load_data(users[0], 0, \"force\")\n",
    "fsra12, fsrb12, fsrc12, fsrd12 = load_data(users[0], 3, \"force\")\n",
    "fsra21, fsrb21, fsrc21, fsrd21 = load_data(users[1], 0, \"force\")\n",
    "fsra22, fsrb22, fsrc22, fsrd22 = load_data(users[1], 3, \"force\")\n",
    "fsra31, fsrb31, fsrc31, fsrd31 = load_data(users[2], 0, \"force\")\n",
    "fsra32, fsrb32, fsrc32, fsrd32 = load_data(users[2], 3, \"force\")\n",
    "fsra41, fsrb41, fsrc41, fsrd41 = load_data(users[2], 0, \"force\")\n",
    "fsra42, fsrb42, fsrc42, fsrd42 = load_data(users[3], 3, \"force\")\n",
    "\n",
    "fsr_1_val_a_1, _, _, fsr_1_mea_a_1, fsr_1_std_a_1 = process_signal(fsra11)\n",
    "fsr_1_val_b_1, _, _, fsr_1_mea_b_1, fsr_1_std_b_1 = process_signal(fsrb11)\n",
    "fsr_1_val_c_1, _, _, fsr_1_mea_c_1, fsr_1_std_c_1 = process_signal(fsrc11)\n",
    "fsr_1_val_d_1, _, _, fsr_1_mea_d_1, fsr_1_std_d_1 = process_signal(fsrd11)\n",
    "fsr_1_val_a_2, _, _, fsr_1_mea_a_2, fsr_1_std_a_2 = process_signal(fsra12)\n",
    "fsr_1_val_b_2, _, _, fsr_1_mea_b_2, fsr_1_std_b_2 = process_signal(fsrb12)\n",
    "fsr_1_val_c_2, _, _, fsr_1_mea_c_2, fsr_1_std_c_2 = process_signal(fsrc12)\n",
    "fsr_1_val_d_2, _, _, fsr_1_mea_d_2, fsr_1_std_d_2 = process_signal(fsrd12)\n",
    "\n",
    "fsr_2_val_a_1, _, _, fsr_2_mea_a_1, fsr_2_std_a_1 = process_signal(fsra21)\n",
    "fsr_2_val_b_1, _, _, fsr_2_mea_b_1, fsr_2_std_b_1 = process_signal(fsrb21)\n",
    "fsr_2_val_c_1, _, _, fsr_2_mea_c_1, fsr_2_std_c_1 = process_signal(fsrc21)\n",
    "fsr_2_val_d_1, _, _, fsr_2_mea_d_1, fsr_2_std_d_1 = process_signal(fsrd21)\n",
    "fsr_2_val_a_2, _, _, fsr_2_mea_a_2, fsr_2_std_a_2 = process_signal(fsra22)\n",
    "fsr_2_val_b_2, _, _, fsr_2_mea_b_2, fsr_2_std_b_2 = process_signal(fsrb22)\n",
    "fsr_2_val_c_2, _, _, fsr_2_mea_c_2, fsr_2_std_c_2 = process_signal(fsrc22)\n",
    "fsr_2_val_d_2, _, _, fsr_2_mea_d_2, fsr_2_std_d_2 = process_signal(fsrd22)\n",
    "\n",
    "fsr_3_val_a_1, _, _, fsr_3_mea_a_1, fsr_3_std_a_1 = process_signal(fsra31)\n",
    "fsr_3_val_b_1, _, _, fsr_3_mea_b_1, fsr_3_std_b_1 = process_signal(fsrb31)\n",
    "fsr_3_val_c_1, _, _, fsr_3_mea_c_1, fsr_3_std_c_1 = process_signal(fsrc31)\n",
    "fsr_3_val_d_1, _, _, fsr_3_mea_d_1, fsr_3_std_d_1 = process_signal(fsrd31)\n",
    "fsr_3_val_a_2, _, _, fsr_3_mea_a_2, fsr_3_std_a_2 = process_signal(fsra32)\n",
    "fsr_3_val_b_2, _, _, fsr_3_mea_b_2, fsr_3_std_b_2 = process_signal(fsrb32)\n",
    "fsr_3_val_c_2, _, _, fsr_3_mea_c_2, fsr_3_std_c_2 = process_signal(fsrc32)\n",
    "fsr_3_val_d_2, _, _, fsr_3_mea_d_2, fsr_3_std_d_2 = process_signal(fsrd32)\n",
    "\n",
    "fsr_4_val_a_1, _, _, fsr_4_mea_a_1, fsr_4_std_a_1 = process_signal(fsra41)\n",
    "fsr_4_val_b_1, _, _, fsr_4_mea_b_1, fsr_4_std_b_1 = process_signal(fsrb41)\n",
    "fsr_4_val_c_1, _, _, fsr_4_mea_c_1, fsr_4_std_c_1 = process_signal(fsrc41)\n",
    "fsr_4_val_d_1, _, _, fsr_4_mea_d_1, fsr_4_std_d_1 = process_signal(fsrd41)\n",
    "fsr_4_val_a_2, _, _, fsr_4_mea_a_2, fsr_4_std_a_2 = process_signal(fsra42)\n",
    "fsr_4_val_b_2, _, _, fsr_4_mea_b_2, fsr_4_std_b_2 = process_signal(fsrb42)\n",
    "fsr_4_val_c_2, _, _, fsr_4_mea_c_2, fsr_4_std_c_2 = process_signal(fsrc42)\n",
    "fsr_4_val_d_2, _, _, fsr_4_mea_d_2, fsr_4_std_d_2 = process_signal(fsrd42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stats = DataFrame(fsr_1_val_a_1, columns=[\"values\"])\n",
    "fig = px.line(stats, y=\"values\")\n",
    "fig.show()\n",
    "stats = DataFrame(fsr_1_val_a_2, columns=[\"values\"])\n",
    "fig = px.line(stats, y=\"values\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Fsr 1 mean values:\")\n",
    "print(fsr_1_mea_a_1)\n",
    "print(fsr_1_mea_a_2)\n",
    "print(fsr_2_mea_a_1)\n",
    "print(fsr_2_mea_a_2)\n",
    "print(fsr_3_mea_a_1)\n",
    "print(fsr_3_mea_a_2)\n",
    "print(fsr_4_mea_a_1)\n",
    "print(fsr_4_mea_a_2)\n",
    "print()\n",
    "print(\"Fsr 2 mean values:\")\n",
    "print(fsr_1_mea_b_1)\n",
    "print(fsr_1_mea_b_2)\n",
    "print(fsr_2_mea_b_1)\n",
    "print(fsr_2_mea_b_2)\n",
    "print(fsr_3_mea_b_1)\n",
    "print(fsr_3_mea_b_2)\n",
    "print(fsr_4_mea_b_1)\n",
    "print(fsr_4_mea_b_2)\n",
    "print()\n",
    "print(\"Fsr 3 mean values:\")\n",
    "print(fsr_1_mea_c_1)\n",
    "print(fsr_1_mea_c_2)\n",
    "print(fsr_2_mea_c_1)\n",
    "print(fsr_2_mea_c_2)\n",
    "print(fsr_3_mea_c_1)\n",
    "print(fsr_3_mea_c_2)\n",
    "print(fsr_4_mea_c_1)\n",
    "print(fsr_4_mea_c_2)\n",
    "print()\n",
    "print(\"Fsr 4 mean values:\")\n",
    "print(fsr_1_mea_d_1)\n",
    "print(fsr_1_mea_d_2)\n",
    "print(fsr_2_mea_d_1)\n",
    "print(fsr_2_mea_d_2)\n",
    "print(fsr_3_mea_d_1)\n",
    "print(fsr_3_mea_d_2)\n",
    "print(fsr_4_mea_d_1)\n",
    "print(fsr_4_mea_d_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Fsr 1 stdn values:\")\n",
    "print(fsr_1_std_a_1)\n",
    "print(fsr_1_std_a_2)\n",
    "print(fsr_2_std_a_1)\n",
    "print(fsr_2_std_a_2)\n",
    "print(fsr_3_std_a_1)\n",
    "print(fsr_3_std_a_2)\n",
    "print(fsr_4_std_a_1)\n",
    "print(fsr_4_std_a_2)\n",
    "print()\n",
    "print(\"Fsr 2 stdn values:\")\n",
    "print(fsr_1_std_b_1)\n",
    "print(fsr_1_std_b_2)\n",
    "print(fsr_2_std_b_1)\n",
    "print(fsr_2_std_b_2)\n",
    "print(fsr_3_std_b_1)\n",
    "print(fsr_3_std_b_2)\n",
    "print(fsr_4_std_b_1)\n",
    "print(fsr_4_std_b_2)\n",
    "print()\n",
    "print(\"Fsr 3 stdn values:\")\n",
    "print(fsr_1_std_c_1)\n",
    "print(fsr_1_std_c_2)\n",
    "print(fsr_2_std_c_1)\n",
    "print(fsr_2_std_c_2)\n",
    "print(fsr_3_std_c_1)\n",
    "print(fsr_3_std_c_2)\n",
    "print(fsr_4_std_c_1)\n",
    "print(fsr_4_std_c_2)\n",
    "print()\n",
    "print(\"Fsr 4 stdn values:\")\n",
    "print(fsr_1_std_d_1)\n",
    "print(fsr_1_std_d_2)\n",
    "print(fsr_2_std_d_1)\n",
    "print(fsr_2_std_d_2)\n",
    "print(fsr_3_std_d_1)\n",
    "print(fsr_3_std_d_2)\n",
    "print(fsr_4_std_d_1)\n",
    "print(fsr_4_std_d_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean crossing rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Fsr 1 stdn values:\")\n",
    "print(mean_crossing_rate(fsr_1_val_a_1, fsr_1_mea_a_1))\n",
    "print(mean_crossing_rate(fsr_1_val_a_2, fsr_1_mea_a_2))\n",
    "print(mean_crossing_rate(fsr_2_val_a_1, fsr_2_mea_a_1))\n",
    "print(mean_crossing_rate(fsr_2_val_a_2, fsr_2_mea_a_2))\n",
    "print(mean_crossing_rate(fsr_3_val_a_1, fsr_3_mea_a_1))\n",
    "print(mean_crossing_rate(fsr_3_val_a_2, fsr_3_mea_a_2))\n",
    "print(mean_crossing_rate(fsr_4_val_a_1, fsr_4_mea_a_1))\n",
    "print(mean_crossing_rate(fsr_4_val_a_2, fsr_4_mea_a_2))\n",
    "print()\n",
    "print(\"Fsr 2 stdn values:\")\n",
    "print(mean_crossing_rate(fsr_1_val_b_1, fsr_1_mea_b_1))\n",
    "print(mean_crossing_rate(fsr_1_val_b_2, fsr_1_mea_b_2))\n",
    "print(mean_crossing_rate(fsr_2_val_b_1, fsr_2_mea_b_1))\n",
    "print(mean_crossing_rate(fsr_2_val_b_2, fsr_2_mea_b_2))\n",
    "print(mean_crossing_rate(fsr_3_val_b_1, fsr_3_mea_b_1))\n",
    "print(mean_crossing_rate(fsr_3_val_b_2, fsr_3_mea_b_2))\n",
    "print(mean_crossing_rate(fsr_4_val_b_1, fsr_4_mea_b_1))\n",
    "print(mean_crossing_rate(fsr_4_val_b_2, fsr_4_mea_b_2))\n",
    "print()\n",
    "print(\"Fsr 3 stdn values:\")\n",
    "print(mean_crossing_rate(fsr_1_val_c_1, fsr_1_mea_c_1))\n",
    "print(mean_crossing_rate(fsr_1_val_c_2, fsr_1_mea_c_2))\n",
    "print(mean_crossing_rate(fsr_2_val_c_1, fsr_2_mea_c_1))\n",
    "print(mean_crossing_rate(fsr_2_val_c_2, fsr_2_mea_c_2))\n",
    "print(mean_crossing_rate(fsr_3_val_c_1, fsr_3_mea_c_1))\n",
    "print(mean_crossing_rate(fsr_3_val_c_2, fsr_3_mea_c_2))\n",
    "print(mean_crossing_rate(fsr_4_val_c_1, fsr_4_mea_c_1))\n",
    "print(mean_crossing_rate(fsr_4_val_c_2, fsr_4_mea_c_2))\n",
    "print()\n",
    "print(\"Fsr 3 stdn values:\")\n",
    "print(mean_crossing_rate(fsr_1_val_d_1, fsr_1_mea_d_1))\n",
    "print(mean_crossing_rate(fsr_1_val_d_2, fsr_1_mea_d_2))\n",
    "print(mean_crossing_rate(fsr_2_val_d_1, fsr_2_mea_d_1))\n",
    "print(mean_crossing_rate(fsr_2_val_d_2, fsr_2_mea_d_2))\n",
    "print(mean_crossing_rate(fsr_3_val_d_1, fsr_3_mea_d_1))\n",
    "print(mean_crossing_rate(fsr_3_val_d_2, fsr_3_mea_d_2))\n",
    "print(mean_crossing_rate(fsr_4_val_d_1, fsr_4_mea_d_1))\n",
    "print(mean_crossing_rate(fsr_4_val_d_2, fsr_4_mea_d_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "users = [\"test_subject_10\", \"test_subject_11\", \"test_subject_12\", \"test_subject_13\"]\n",
    "cpua11, cpub11, cpuc11, cpud11 = load_data(users[0], 0, \"cpu\")\n",
    "cpua12, cpub12, cpuc12, cpud12 = load_data(users[0], 3, \"cpu\")\n",
    "cpua21, cpub21, cpuc21, cpud21 = load_data(users[1], 0, \"cpu\")\n",
    "cpua22, cpub22, cpuc22, cpud22 = load_data(users[1], 3, \"cpu\")\n",
    "cpua31, cpub31, cpuc31, cpud31 = load_data(users[2], 0, \"cpu\")\n",
    "cpua32, cpub32, cpuc32, cpud32 = load_data(users[2], 3, \"cpu\")\n",
    "cpua41, cpub41, cpuc41, cpud41 = load_data(users[3], 0, \"cpu\")\n",
    "cpua42, cpub42, cpuc42, cpud42 = load_data(users[3], 3, \"cpu\")\n",
    "\n",
    "cpu_1_val_a_1, _, _, cpu_1_mea_a_1, _ = process_signal(cpua11)\n",
    "cpu_1_val_b_1, _, _, cpu_1_mea_b_1, _ = process_signal(cpub11)\n",
    "cpu_1_val_c_1, _, _, cpu_1_mea_c_1, _ = process_signal(cpuc11)\n",
    "cpu_1_val_d_1, _, _, cpu_1_mea_d_1, _ = process_signal(cpud11)\n",
    "cpu_1_val_1, cpu_1_mea_1, _ = join_cpu_signals(cpu_1_val_a_1, cpu_1_val_b_1, cpu_1_val_c_1, cpu_1_val_d_1)\n",
    "\n",
    "cpu_1_val_a_2, _, _, cpu_1_mea_a_2, _ = process_signal(cpua12)\n",
    "cpu_1_val_b_2, _, _, cpu_1_mea_b_2, _ = process_signal(cpub12)\n",
    "cpu_1_val_c_2, _, _, cpu_1_mea_c_2, _ = process_signal(cpuc12)\n",
    "cpu_1_val_d_2, _, _, cpu_1_mea_d_2, _ = process_signal(cpud12)\n",
    "cpu_1_val_2, cpu_1_mea_2, _ = join_cpu_signals(cpu_1_val_a_2, cpu_1_val_b_2, cpu_1_val_c_2, cpu_1_val_d_2)\n",
    "\n",
    "cpu_2_val_a_1, _, _, cpu_2_mea_a_1, _ = process_signal(cpua21)\n",
    "cpu_2_val_b_1, _, _, cpu_2_mea_b_1, _ = process_signal(cpub21)\n",
    "cpu_2_val_c_1, _, _, cpu_2_mea_c_1, _ = process_signal(cpuc21)\n",
    "cpu_2_val_d_1, _, _, cpu_2_mea_d_1, _ = process_signal(cpud21)\n",
    "cpu_2_val_1, cpu_2_mea_1, _ = join_cpu_signals(cpu_2_val_a_1, cpu_2_val_b_1, cpu_2_val_c_1, cpu_2_val_d_1)\n",
    "\n",
    "cpu_2_val_a_2, _, _, cpu_2_mea_a_2, _ = process_signal(cpua22)\n",
    "cpu_2_val_b_2, _, _, cpu_2_mea_b_2, _ = process_signal(cpub22)\n",
    "cpu_2_val_c_2, _, _, cpu_2_mea_c_2, _ = process_signal(cpuc22)\n",
    "cpu_2_val_d_2, _, _, cpu_2_mea_d_2, _ = process_signal(cpud22)\n",
    "cpu_2_val_2, cpu_2_mea_2, _ = join_cpu_signals(cpu_2_val_a_2, cpu_2_val_b_2, cpu_2_val_c_2, cpu_2_val_d_2)\n",
    "\n",
    "cpu_3_val_a_1, _, _, cpu_3_mea_a_1, _ = process_signal(cpua31)\n",
    "cpu_3_val_b_1, _, _, cpu_3_mea_b_1, _ = process_signal(cpub31)\n",
    "cpu_3_val_c_1, _, _, cpu_3_mea_c_1, _ = process_signal(cpuc31)\n",
    "cpu_3_val_d_1, _, _, cpu_3_mea_d_1, _ = process_signal(cpud31)\n",
    "cpu_3_val_1, cpu_3_mea_1, _ = join_cpu_signals(cpu_3_val_a_1, cpu_3_val_b_1, cpu_3_val_c_1, cpu_3_val_d_1)\n",
    "\n",
    "cpu_3_val_a_2, _, _, cpu_3_mea_a_2, _ = process_signal(cpua32)\n",
    "cpu_3_val_b_2, _, _, cpu_3_mea_b_2, _ = process_signal(cpub32)\n",
    "cpu_3_val_c_2, _, _, cpu_3_mea_c_2, _ = process_signal(cpuc32)\n",
    "cpu_3_val_d_2, _, _, cpu_3_mea_d_2, _ = process_signal(cpud32)\n",
    "cpu_3_val_2, cpu_3_mea_2, _ = join_cpu_signals(cpu_3_val_a_2, cpu_3_val_b_2, cpu_3_val_c_2, cpu_3_val_d_2)\n",
    "\n",
    "cpu_4_val_a_1, _, _, cpu_4_mea_a_1, _ = process_signal(cpua41)\n",
    "cpu_4_val_b_1, _, _, cpu_4_mea_b_1, _ = process_signal(cpub41)\n",
    "cpu_4_val_c_1, _, _, cpu_4_mea_c_1, _ = process_signal(cpuc41)\n",
    "cpu_4_val_d_1, _, _, cpu_4_mea_d_1, _ = process_signal(cpud41)\n",
    "cpu_4_val_1, cpu_4_mea_1, _ = join_cpu_signals(cpu_4_val_a_1, cpu_4_val_b_1, cpu_4_val_c_1, cpu_4_val_d_1)\n",
    "\n",
    "cpu_4_val_a_2, _, _, cpu_4_mea_a_2, _ = process_signal(cpua42)\n",
    "cpu_4_val_b_2, _, _, cpu_4_mea_b_2, _ = process_signal(cpub42)\n",
    "cpu_4_val_c_2, _, _, cpu_4_mea_c_2, _ = process_signal(cpuc42)\n",
    "cpu_4_val_d_2, _, _, cpu_4_mea_d_2, _ = process_signal(cpud42)\n",
    "cpu_4_val_2, cpu_4_mea_2, _ = join_cpu_signals(cpu_4_val_a_2, cpu_4_val_b_2, cpu_4_val_c_2, cpu_4_val_d_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stats = {\"avg_load\": [], \"min_load\": [], \"max_load\": [], \"mean_crossing_rate\": []}\n",
    "\n",
    "for val, mea in zip(\n",
    "    [cpu_1_val_1, cpu_1_val_2, cpu_2_val_1, cpu_2_val_2, cpu_3_val_1, cpu_3_val_2, cpu_4_val_1, cpu_4_val_2],\n",
    "    [cpu_1_mea_1, cpu_1_mea_2, cpu_2_mea_1, cpu_2_mea_2, cpu_3_mea_1, cpu_3_mea_2, cpu_4_mea_1, cpu_4_mea_2]\n",
    "):\n",
    "    stats[\"avg_load\"].append(mean(val))\n",
    "    stats[\"min_load\"].append(min(val))\n",
    "    stats[\"max_load\"].append(max(val))\n",
    "    stats[\"mean_crossing_rate\"].append(mean_crossing_rate(val, mea))\n",
    "    \n",
    "stats = DataFrame(stats)\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "users = [\"test_subject_10\", \"test_subject_11\", \"test_subject_12\", \"test_subject_13\"]\n",
    "ram11 = load_data(users[0], 0, \"ram\")\n",
    "ram12 = load_data(users[0], 3, \"ram\")\n",
    "ram21 = load_data(users[1], 0, \"ram\")\n",
    "ram22 = load_data(users[1], 3, \"ram\")\n",
    "ram31 = load_data(users[2], 0, \"ram\")\n",
    "ram32 = load_data(users[2], 3, \"ram\")\n",
    "ram41 = load_data(users[3], 0, \"ram\")\n",
    "ram42 = load_data(users[3], 3, \"ram\")\n",
    "\n",
    "ram_1_val_1, _, _, _, _ = process_signal(ram11)\n",
    "ram_1_val_2, _, _, _, _ = process_signal(ram12)\n",
    "ram_2_val_1, _, _, _, _ = process_signal(ram21)\n",
    "ram_2_val_2, _, _, _, _ = process_signal(ram22)\n",
    "ram_3_val_1, _, _, _, _ = process_signal(ram31)\n",
    "ram_3_val_2, _, _, _, _ = process_signal(ram32)\n",
    "ram_4_val_1, _, _, _, _ = process_signal(ram41)\n",
    "ram_4_val_2, _, _, _, _ = process_signal(ram42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def find_ram_jump(signal):\n",
    "    derivative = []\n",
    "    prev = signal[0]\n",
    "    for curr in signal[1:]:\n",
    "        derivative.append(abs(curr-prev))\n",
    "        prev = curr\n",
    "    peaks, _ = find_peaks(derivative, threshold=0.25)\n",
    "    \n",
    "    p = {\"position\": [], \"magnitude\": []}\n",
    "    for x in peaks:\n",
    "        p[\"position\"].append(x)\n",
    "        p[\"magnitude\"].append(derivative[x])\n",
    "    return derivative, p\n",
    "\n",
    "stats = {\"avg_load\":[], \"min_load\":[], \"max_load\":[], \"jump_count\":[], \"jump_rate\":[], \"avg_jump_value\":[], \"avg_inter_jump_interval\":[]}\n",
    "\n",
    "for x in [ram_1_val_1, ram_1_val_2, ram_2_val_1, ram_2_val_2, ram_3_val_1, ram_3_val_2, ram_4_val_1, ram_4_val_2]:\n",
    "    derivatives, peaks = find_ram_jump(x)\n",
    "    val = DataFrame(x, columns=[\"values\"])\n",
    "    der = DataFrame(derivatives, columns=[\"values\"])\n",
    "    pea = DataFrame(peaks)\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            name=\"Value\",\n",
    "            x=val.index.values,\n",
    "            y=val[\"values\"],\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            name=\"Derivative\",\n",
    "            x=der.index.values,\n",
    "            y=der[\"values\"],\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            name=\"Peak\",\n",
    "            x=pea[\"position\"],\n",
    "            y=pea[\"magnitude\"],\n",
    "            mode=\"markers\",\n",
    "        )\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "    # Calculate average inter jump interval\n",
    "    prev = peaks[\"position\"][0]\n",
    "    intervals = []\n",
    "    for curr in peaks[\"position\"][1:]:\n",
    "        intervals.append(curr-prev)\n",
    "        prev = curr\n",
    "    avg_load = round(mean(x), 2)\n",
    "    min_load = min(x)\n",
    "    max_load = max(x)\n",
    "    jump_count = len(peaks[\"position\"])\n",
    "    jump_rate = round(len(peaks[\"position\"])/len(derivatives), 2)\n",
    "    avg_jump_value = round(mean(peaks[\"magnitude\"]), 2)\n",
    "    avg_inter_jump_interval = round(mean(intervals), 2)\n",
    "    print(\"Average load: \\t\\t\\t{}\".format(avg_load))\n",
    "    print(\"Minimum load: \\t\\t\\t{}\".format(min_load))\n",
    "    print(\"Maximum load: \\t\\t\\t{}\".format(max_load))\n",
    "    print(\"Jump count: \\t\\t\\t{}\".format(jump_count))\n",
    "    print(\"Jump rate: \\t\\t\\t{}\".format(jump_rate))\n",
    "    print(\"Average jump value: \\t\\t{}\".format(avg_jump_value))\n",
    "    print(\"Average inter jump interval: \\t{}\".format(avg_inter_jump_interval))\n",
    "    \n",
    "    stats[\"avg_load\"].append(avg_load)\n",
    "    stats[\"min_load\"].append(min_load)\n",
    "    stats[\"max_load\"].append(max_load)\n",
    "    stats[\"jump_count\"].append(jump_count)\n",
    "    stats[\"jump_rate\"].append(jump_rate)\n",
    "    stats[\"avg_jump_value\"].append(avg_jump_value)\n",
    "    stats[\"avg_inter_jump_interval\"].append(avg_inter_jump_interval)\n",
    "\n",
    "stats = DataFrame(stats)\n",
    "print()\n",
    "print(stats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network activity overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "users = [\"test_subject_10\", \"test_subject_11\", \"test_subject_12\", \"test_subject_13\"]\n",
    "# Take only packet received data\n",
    "_, net11 = load_data(users[0], 0, \"net\")\n",
    "_, net12 = load_data(users[0], 3, \"net\")\n",
    "_, net21 = load_data(users[1], 0, \"net\")\n",
    "_, net22 = load_data(users[1], 3, \"net\")\n",
    "_, net31 = load_data(users[2], 0, \"net\")\n",
    "_, net32 = load_data(users[2], 3, \"net\")\n",
    "_, net41 = load_data(users[3], 0, \"net\")\n",
    "_, net42 = load_data(users[3], 3, \"net\")\n",
    "\n",
    "# Take only packet sent data\n",
    "# net11, _ = load_data(users[0], 0, \"net\")\n",
    "# net12, _ = load_data(users[0], 3, \"net\")\n",
    "# net21, _ = load_data(users[1], 0, \"net\")\n",
    "# net22, _ = load_data(users[1], 3, \"net\")\n",
    "# net31, _ = load_data(users[2], 0, \"net\")\n",
    "# net32, _ = load_data(users[2], 3, \"net\")\n",
    "# net41, _ = load_data(users[3], 0, \"net\")\n",
    "# net42, _ = load_data(users[3], 3, \"net\")\n",
    "\n",
    "net_1_val_1, _, _, _, _ = process_signal(net11)\n",
    "net_1_val_2, _, _, _, _ = process_signal(net12)\n",
    "net_2_val_1, _, _, _, _ = process_signal(net21)\n",
    "net_2_val_2, _, _, _, _ = process_signal(net22)\n",
    "net_3_val_1, _, _, _, _ = process_signal(net31)\n",
    "net_3_val_2, _, _, _, _ = process_signal(net32)\n",
    "net_4_val_1, _, _, _, _ = process_signal(net41)\n",
    "net_4_val_2, _, _, _, _ = process_signal(net42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "¨¨¨\n",
    "\n",
    "stats = DataFrame(stats)\n",
    "print()\n",
    "print(stats)\n",
    "\n",
    "# normalize sum load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pir sensors overview\n",
    "- Id 58: pir_01\n",
    "- Id 59: pir_02\n",
    "- Id 66: pir_03\n",
    "- Id 67: pir_04\n",
    "- Id 68: pir_05\n",
    "- Id 69: pir_06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pir_1, s_sta_1, s_end_1 = load_data(\"test_subject_10\", 2, \"pir\")\n",
    "pir_2, s_sta_2, s_end_2 = load_data(\"test_subject_11\", 2, \"pir\")\n",
    "pir_3, s_sta_3, s_end_3 = load_data(\"test_subject_12\", 2, \"pir\")\n",
    "pir_4, s_sta_4, s_end_4 = load_data(\"test_subject_13\", 2, \"pir\")\n",
    "\n",
    "pir_val_1, pir_tim_1, pir_ids_1 = process_binary_signal(pir_1)\n",
    "pir_val_2, pir_tim_2, pir_ids_2 = process_binary_signal(pir_2)\n",
    "pir_val_3, pir_tim_3, pir_ids_3 = process_binary_signal(pir_3)\n",
    "pir_val_4, pir_tim_4, pir_ids_4 = process_binary_signal(pir_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def detect_pir_activity_type(start, end, values, times, ids, time_interval: timedelta=timedelta(seconds=30)):\n",
    "    \"\"\"\n",
    "    For every given time interval, check which sensors were active and \n",
    "    based on that classify each time interval into one of 3 activities:\n",
    "    - no activity (no sensors active)\n",
    "    - seating (senor pir_01 active)\n",
    "    - moving (more than one sensor active)\n",
    "    \"\"\"\n",
    "    if not (len(values) == len(times) and len(times) == len(ids)):\n",
    "        raise ValueError(\"Mismatching value lengths.\")\n",
    "    intervals = create_time_chunks(start, end, time_interval)\n",
    "    result = []\n",
    "    active = []\n",
    "    \n",
    "    for interval in intervals:\n",
    "        prev = []\n",
    "        interval_ids = [index for index, value in enumerate(times) if interval[0] <= value <= interval[1]]\n",
    "        for idx in interval_ids:\n",
    "            if not values[idx]:\n",
    "                try:\n",
    "                    active.remove(ids[idx])\n",
    "                    prev.append(ids[idx])\n",
    "                except:\n",
    "                    pass\n",
    "            elif ids[idx] not in active:\n",
    "                active.append(ids[idx])\n",
    "        result.append({\"interval\": interval, \"ids\": set(prev + active)})\n",
    "        prev = active\n",
    "        \n",
    "    for res in result:\n",
    "        if len(res[\"ids\"]) > 1 or len(res[\"ids\"]) == 1 and res[\"ids\"] != 58:\n",
    "            res.update({\"activity\": \"movement\"})\n",
    "        elif len(res[\"ids\"]) == 1 and res[\"ids\"] == 58:\n",
    "            res.update({\"activity\": \"seated\"})\n",
    "        else:\n",
    "            res.update({\"activity\": \"no activity\"})\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_activity_vector(intervals):\n",
    "    \"\"\"\n",
    "    Create an enum vector from pir activity intervals.\n",
    "    \"\"\"\n",
    "    result_vector = []\n",
    "    for x in intervals:\n",
    "        if x[\"activity\"] == \"no activity\":\n",
    "            result_vector.append(0)\n",
    "        elif x[\"activity\"] == \"seated\":\n",
    "            result_vector.append(1)\n",
    "        elif x[\"activity\"] == \"movement\":\n",
    "            result_vector.append(2)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown activity class.\")\n",
    "    return result_vector\n",
    "    \n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "    \n",
    "seconds = 5\n",
    "intervals_1 = detect_pir_activity_type(s_sta_1, s_end_1, pir_val_1, pir_tim_1, pir_ids_1, timedelta(seconds=seconds))\n",
    "intervals_2 = detect_pir_activity_type(s_sta_2, s_end_2, pir_val_2, pir_tim_2, pir_ids_2, timedelta(seconds=seconds))\n",
    "intervals_3 = detect_pir_activity_type(s_sta_3, s_end_3, pir_val_3, pir_tim_3, pir_ids_3, timedelta(seconds=seconds))\n",
    "intervals_4 = detect_pir_activity_type(s_sta_4, s_end_4, pir_val_4, pir_tim_4, pir_ids_4, timedelta(seconds=seconds))\n",
    "\n",
    "print(get_activity_vector(intervals_1))\n",
    "print(get_activity_vector(intervals_2))\n",
    "print(get_activity_vector(intervals_3))\n",
    "print(get_activity_vector(intervals_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hall sensor overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv, DataFrame, concat, Series\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from numpy import nan_to_num\n",
    "from plotly.express import scatter, scatter_3d\n",
    "\n",
    "def perform_pca(df, comp_num=2):\n",
    "    features = [x for x in range(2, 58)]\n",
    "    data = df.iloc[:, features]\n",
    "    data.fillna(0)\n",
    "    x = df.loc[:, features].values\n",
    "    x = StandardScaler().fit_transform(x)\n",
    "    x = nan_to_num(x)\n",
    "    y = list(df.loc[:, 0])\n",
    "    z = [0.0125 if a <= 2 else 0.025 for a in list(df.loc[:, 1])]\n",
    "    pca = PCA(n_components=comp_num)\n",
    "    principalComponents = pca.fit_transform(x)\n",
    "    print(pca.explained_variance_ratio_)\n",
    "    if comp_num == 2:\n",
    "        return concat([DataFrame(data = principalComponents, columns = ['component 1', 'component 2']), DataFrame(y, columns=[\"label\"]), DataFrame(z, columns=[\"experiment\"])], axis=1)\n",
    "    elif comp_num == 3:\n",
    "        return concat([DataFrame(data = principalComponents, columns = ['component 1', 'component 2', 'component 3']), DataFrame(y, columns=[\"label\"]), DataFrame(z, columns=[\"experiment\"])], axis=1)\n",
    "    else:\n",
    "        raise ValueError(\"Number of components limited to 2 or 3.\")\n",
    "df = read_csv(\"processed_data.csv\", header=None)\n",
    "\n",
    "df_0 = df[df.iloc[:, 1] == 0].copy()\n",
    "df_3 = df[df.iloc[:, 1] == 3].copy()\n",
    "df_03 = concat([df_0, df_3])\n",
    "\n",
    "df_1 = df[df.iloc[:, 1] == 1].copy()\n",
    "df_4 = df[df.iloc[:, 1] == 4].copy()\n",
    "df_14 = concat([df_1, df_4])\n",
    "\n",
    "df_2 = df[df.iloc[:, 1] == 2].copy()\n",
    "df_5 = df[df.iloc[:, 1] == 5].copy()\n",
    "df_25 = concat([df_2, df_5])\n",
    "\n",
    "fig = scatter(perform_pca(df_03), x=\"component 1\", y=\"component 2\", color=\"label\", size=\"experiment\")\n",
    "fig.show()\n",
    "fig = scatter(perform_pca(df_14), x=\"component 1\", y=\"component 2\", color=\"label\", size=\"experiment\")\n",
    "fig.show()\n",
    "fig = scatter(perform_pca(df_25), x=\"component 1\", y=\"component 2\", color=\"label\", size=\"experiment\")\n",
    "fig.show()\n",
    "\n",
    "fig = scatter_3d(perform_pca(df_03, comp_num=3), x=\"component 1\", y=\"component 2\", z=\"component 3\", color=\"label\", size=\"experiment\")\n",
    "fig.show()\n",
    "fig = scatter_3d(perform_pca(df_14, comp_num=3), x=\"component 1\", y=\"component 2\", z=\"component 3\", color=\"label\", size=\"experiment\")\n",
    "fig.show()\n",
    "fig = scatter_3d(perform_pca(df_25, comp_num=3), x=\"component 1\", y=\"component 2\", z=\"component 3\", color=\"label\", size=\"experiment\")\n",
    "fig.show()\n",
    "\n",
    "# add dimension to graphs to separate first and second try of each experiment\n",
    "# https://stackoverflow.com/questions/50796024/feature-variable-importance-after-a-pca-analysis\n",
    "# clustering quality metrics per experiment per user (compare with random)\n",
    "# plot by features (without pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "#In general a good idea is to scale the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)    \n",
    "\n",
    "\n",
    "features = [x for x in range(2, 58)]\n",
    "data = df.iloc[:, features]\n",
    "data.fillna(0)\n",
    "x = df.loc[:, features].values\n",
    "x = StandardScaler().fit_transform(x)\n",
    "x = nan_to_num(x)\n",
    "y = list(df.loc[:, 0])\n",
    "z = [0.0125 if a <= 2 else 0.025 for a in list(df.loc[:, 1])]\n",
    "pca = PCA(n_components=comp_num)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "\n",
    "pca = PCA()\n",
    "x_new = pca.fit_transform(X)\n",
    "\n",
    "def myplot(score,coeff,labels=None):\n",
    "    xs = score[:,0]\n",
    "    ys = score[:,1]\n",
    "    n = coeff.shape[0]\n",
    "    scalex = 1.0/(xs.max() - xs.min())\n",
    "    scaley = 1.0/(ys.max() - ys.min())\n",
    "    plt.scatter(xs * scalex,ys * scaley, c = y)\n",
    "    for i in range(n):\n",
    "        plt.arrow(0, 0, coeff[i,0], coeff[i,1],color = 'r',alpha = 0.5)\n",
    "        if labels is None:\n",
    "            plt.text(coeff[i,0]* 1.15, coeff[i,1] * 1.15, \"Var\"+str(i+1), color = 'g', ha = 'center', va = 'center')\n",
    "        else:\n",
    "            plt.text(coeff[i,0]* 1.15, coeff[i,1] * 1.15, labels[i], color = 'g', ha = 'center', va = 'center')\n",
    "plt.xlim(-1,1)\n",
    "plt.ylim(-1,1)\n",
    "plt.xlabel(\"PC{}\".format(1))\n",
    "plt.ylabel(\"PC{}\".format(2))\n",
    "plt.grid()\n",
    "\n",
    "print(x_new[:,0:2])\n",
    "print(np.transpose(pca.components_[0:2, :]))\n",
    "#Call the function. Use only the 2 PCs.\n",
    "myplot(x_new[:,0:2],np.transpose(pca.components_[0:2, :]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def get_random_users(n=3):\n",
    "    users = []\n",
    "    while len(users) < n:\n",
    "        user = random.randint(7,27)\n",
    "        if user not in users:\n",
    "            users.append(user)\n",
    "    print(\"Users: {}\".format(users))\n",
    "    return users\n",
    "    \n",
    "def get_lda(data, users):\n",
    "    data = data[data.user.isin(users)]\n",
    "    X = data.iloc[:, 2:].values\n",
    "    y = data.iloc[:, 0].values.ravel()\n",
    "    z = data.iloc[:, 1].values.ravel()\n",
    "    lda = LinearDiscriminantAnalysis(n_components = 2)\n",
    "    X_lda = lda.fit_transform(X, y)\n",
    "    print(lda.explained_variance_ratio_)\n",
    "        \n",
    "    y = y.reshape(len(y), 1)\n",
    "    z = z.reshape(len(z), 1)\n",
    "    df = [list(y) + list(z) + list(x) for x, y, z in zip(X_lda, y, z)]\n",
    "    return DataFrame(df, columns=[\"user\", \"try\", \"component_1\", \"component_2\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get n random users\n",
    "user_number = 5\n",
    "users = get_random_users(n=user_number)\n",
    "\n",
    "# Plot all segment intervals into subplots\n",
    "fig = make_subplots(rows=2, cols=5, subplot_titles=[\"10 seconds\", \"15 seconds\", \"30 seconds\", \"45 seconds\", \"60 seconds\", \"75 seconds\", \"90 seconds\", \"120 seconds\", \"150 seconds\", \"180 seconds\"])\n",
    "for i in range(0, len(datas)):\n",
    "    lda = get_lda(datas[i], users)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=lda[\"component_1\"],\n",
    "            y=lda[\"component_2\"],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                color=lda[\"user\"], #set color equal to a variable\n",
    "                colorscale='rainbow', # one of plotly colorscales\n",
    "            )),    \n",
    "        row=int(i/5) + 1, \n",
    "        col=i%5 + 1\n",
    "    )\n",
    "fig.update_layout(title=\"Number of users: {}\".format(user_number))\n",
    "fig.show()\n",
    "\n",
    "# Plot each segment interval into its own plot\n",
    "for i in range(0, len(datas)):\n",
    "    lda = get_lda(datas[i], users)\n",
    "    fig = scatter(lda, x=\"component_1\", y=\"component_2\", color=\"user\", color_continuous_scale='Rainbow', title=\"Number of users: {}, segment interval: {} seconds\".format(user_number, segment_intervals[i]))\n",
    "#     fig.update_xaxes(range=[-50, 50])\n",
    "#     fig.update_yaxes(range=[-50, 50])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
